
@paper{
	Bastian:2009,
	author = {
		Mathieu Bastian   and
		Sebastien Heymann and
		Mathieu Jacomy
	},
	title = {
		Gephi: An Open Source Software for Exploring and Manipulating Networks
	},
	conference = {
		International AAAI Conference on Weblogs and Social Media
	},
	year = { 2009 },
	keywords = {
		network;
        network science;
        visualization;
        graph exploration;
        open source;
        free software;
        dynamic network;
        interactive interface;graph;
        force vector;java;OpenGL;
        3-D visualization;
        user-centric;
        graph layout;
        complex graph rendering;
        network analysis;
        webatlas
	},
	abstract = {
		Gephi is an open source software for graph and network analysis. It uses
		a 3D render engine to display large networks in real-time and to speed
		up the exploration. A flexible and multi-task architecture brings new
		possibilities to work with complex data sets and produce valuable visual
		results. We present several key features of Gephi in the context of
		interactive exploration and interpretation of networks. It provides easy
		and broad access to network data and allows for spatializing, filtering,
		navigating, manipulating and clustering. Finally, by presenting dynamic
		features of Gephi, we highlight key aspects of dynamic network
		visualization.
	},
	url = { http://www.aaai.org/ocs/index.php/ICWSM/09/paper/view/154 }
}

@article{
	Pinaud:2012,
	author = {
		Bruno Pinaud      and
		Guy Melan{\c c}on and
		Jonathan Dubois
	},
	title = {
		PORGY: A Visual Graph Rewriting Environment for Complex Systems
	},
	journal = { Computer Graphics Forum },
	publisher = { Blackwell Publishing },
	volume = { 31 },
	number = { 3 },
	pages = { 1265-1274 },
	year = { 2012 },
	doi = { 10.1111/j.1467-8659.2012.03119.x },
	url = { http://hal.archives-ouvertes.fr/hal-00682550 }
}

@inproceedings{
	Zaidi:2012,
	author = {
		Faraz Zaidi and
		Guy Melan{\c c}on
	},
	title = {
		Topological Decomposition and Heuristics for High Speed Clustering of
		Complex Networks
	},
	booktitle = { Extraction et Gestion de Connaissance, 2012 },
	year = { 2012 },
	month = Jan,
	editor = { Hermann },
	volume = { RNTI-E-23 },
	pages = { 447-458 },
	keywords = { Clustering; Complex Networks; High Speed Clustering },
	address = { Bordeaux, France },
	url = { http://hal.archives-ouvertes.fr/hal-00679668 }
}

@inproceedings{
	Auber:2010,
	author = {
		David Auber        and
		Patrick Mary       and
		Morgan Mathiaut    and
		Jonathan Dubois    and
		Antoine Lambert    and
		Daniel Archambault and
		Romain Bourqui     and
		Bruno Pinaud       and
		Maylis Delest      and
		Guy Melan{\c c}on
	},
	title = { Tulip: a Scalable Graph Visualization Framework },
	booktitle = { Extraction et Gestion des Connaissances (EGC) 2010 },
	year = { 2010 },
	month = Jan,
	editor = { Sadok Ben Yahia and Jean-Marc Petit },
	publisher = { RNTI },
	volume = { RNTI E-19 },
	pages = { 623-624 },
	address = { Hammamet, Tunisia },
	url = { http://hal.archives-ouvertes.fr/inria-00482563 }
}

@inproceedings{
	Ellson:2001,
    author = {
		John Ellson         and
		Emden Gansner       and
		Lefteris Koutsofios and
		Stephen North       and
		Gordon Woodhull
	},
    title = { Graphviz — open source graph drawing tools },
    booktitle = { Lecture Notes in Computer Science },
    year = { 2001 },
    pages = { 483--484 },
    publisher = { Springer-Verlag }
}

@article{
	Gansner:2000,
	author = {
		Emden R. Gansner and
		Stephen C.  North
	},
	title = {
		An Open Graph Visualization System and Its Applications to Software
		Engineering
	},
	journal = { Softw. Pract. Exper. },
	issue_date = { Sept. 2000 },
	volume = { 30 },
	number = { 11 },
	month = sep,
	year = { 2000 },
	issn = { 0038-0644 },
	pages = { 1203--1233 },
	numpages = { 31 },
	url = {
		http://dx.doi.org/10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.3.CO;2-E
	},
	doi = { 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.3.CO;2-E },
	acmid = { 358697 },
	publisher = { John Wiley \& Sons, Inc. },
	address = { New York, NY, USA },
	keywords = { graph visualization, open systems, software engineering },
}

@article{
    Landge:2012,
    author = {
        Landge, A.G. and
        Levine, J.A. and
        Bhatele, A. and
        Isaacs, K.E. and
        Gamblin, T. and
        Schulz, M. and
        Langer, S.H. and
        Bremer, P.-T. and
        Pascucci, V.
    }, 
    journal = { Visualization and Computer Graphics, IEEE Transactions on },
    title = {
        Visualizing Network Traffic to Understand the Performance of Massively
        Parallel Simulations
    },
    year = { 2012 },
    month = { Dec },
    volume = { 18 },
    number = { 12 },
    pages = { 2467-2476 },
    abstract = {
        The performance of massively parallel applications is often heavily
        impacted by the cost of communication among compute nodes. However,
        determining how to best use the network is a formidable task, made
        challenging by the ever increasing size and complexity of modern
        supercomputers. This paper applies visualization techniques to aid
        parallel application developers in understanding the network activity by
        enabling a detailed exploration of the flow of packets through the
        hardware interconnect. In order to visualize this large and complex
        data, we employ two linked views of the hardware network. The first is a
        2D view, that represents the network structure as one of several
        simplified planar projections. This view is designed to allow a user to
        easily identify trends and patterns in the network traffic. The second
        is a 3D view that augments the 2D view by preserving the physical
        network topology and providing a context that is familiar to the
        application developers. Using the massively parallel multi-physics code
        pF3D as a case study, we demonstrate that our tool provides valuable
        insight that we use to explain and optimize pF3D's performance on an IBM
        Blue Gene/P system.
    },
    keywords = {
        data visualisation;
        laser beams;
        mainframes;
        network topology;
        parallel processing;
        physics computing;
        plasma simulation;
        plasma-beam interactions;
        2D view;
        3D view;
        IBM Blue Gene-P system;
        compute nodes;
        data visualization;
        hardware interconnect;
        laser interaction;
        network structure;
        network traffic visualization;
        packet flow;
        parallel application developers;
        parallel multiphysics code pF3D;
        parallel simulation performance;
        physical network topology;
        plasma interaction;
        supercomputers;
        Computational modeling;
        Data visualization;
        Hardware;
        Layout;
        Network topology;
        Performance evaluation;
        Supercomputers;
        Performance analysis;
        network traffic visualization;
        projected graph layouts
    },
    doi = { 10.1109/TVCG.2012.286 },
    ISSN = { 1077-2626 }
}

@inproceedings{
    Bhatia:2005,
    author = {
        Bhatia, N. and
        Fengguang Song and
        Wolf, F. and
        Dongarra, J. and
        Mohr, B. and
        Moore, S.
    },
    booktitle = {
        Parallel Processing, 2005. ICPP 2005. International Conference on
    },
    title = {
        Automatic experimental analysis of communication patterns in virtual
        topologies
    },
    year = { 2005 },
    month = { June },
    pages = { 465-472 },
    abstract = {
        Automatic pattern search in event traces is a powerful method to
        identify performance problems in parallel applications. We demonstrate
        that knowledge about the virtual topology, which defines logical
        adjacency relationships between processes, can be exploited to explain
        the occurrence of inefficiency patterns in terms of the parallelization
        strategy used in an application. We show correlations between
        higher-level events related to a parallel wavefront scheme and wait
        states identified by our pattern analysis. In addition, we visually
        expose relationships between pattern occurrences and the topological
        characteristics of the affected processes.
    },
    keywords = {
        multiprocessing systems;
        network topology;
        parallel processing;
        communication pattern;
        event tracing;
        parallel wavefront scheme;
        virtual topology;
        Concurrent computing;
        Feedback;
        Hardware;
        Lifting equipment;
        Parallel algorithms;
        Pattern analysis;
        Performance analysis;
        Topology;
        Visualization;
        Yarn;
        event tracing;
        performance tools;
        virtual topologies;
        visualization;
        wavefront algorithms
    },
    doi = { 10.1109/ICPP.2005.21 },
    ISSN = { 0190-3918 }
}

@article{
    Muelder:2009,
    author = {
        Muelder, C. and
        Gygi, F. and
        Kwan-Liu Ma
    },
    journal = { Visualization and Computer Graphics, IEEE Transactions on },
    title = {
        Visual Analysis of Inter-Process Communication for Large-Scale Parallel
        Computing
    },
    year = { 2009 },
    month = { Nov },
    volume = { 15 },
    number = { 6 },
    pages = { 1129-1136 },
    abstract = {
        In serial computation, program profiling is often helpful for
        optimization of key sections of code. When moving to parallel
        computation, not only does the code execution need to be considered but
        also communication between the different processes which can induce
        delays that are detrimental to performance. As the number of processes
        increases, so does the impact of the communication delays on
        performance. For large-scale parallel applications, it is critical to
        understand how the communication impacts performance in order to make
        the code more efficient. There are several tools available for
        visualizing program execution and communications on parallel systems.
        These tools generally provide either views which statistically summarize
        the entire program execution or process-centric views. However,
        process-centric visualizations do not scale well as the number of
        processes gets very large. In particular, the most common representation
        of parallel processes is a Gantt chart with a row for each process. As
        the number of processes increases, these charts can become difficult to
        work with and can even exceed screen resolution. We propose a new
        visualization approach that affords more scalability and then
        demonstrate it on systems running with up to 16,384 processes.
    },
    keywords = {
        application program interfaces;
        data visualisation;
        message passing;
        Gantt chart;
        MPI Profiling;
        information visualization;
        interprocess communication;
        large-scale parallel computing;
        parallel processes;
        parallel systems;
        program execution;
        program profiling;
        visual analysis;
        Computational modeling;
        Delay;
        Laboratories;
        Large-scale systems;
        Message passing;
        Parallel processing;
        Scalability;
        Supercomputers;
        US Department of Energy;
        Visualization;
        Information Visualization;
        MPI Profiling;Scalability
    }, 
    doi = { 10.1109/TVCG.2009.196 },
    ISSN = { 1077-2626 }
}

@inproceedings{
    Lee:2008,
    author = {
        Chee Wai Lee and
        Mendes, C. and
        Kale, L.V.
    },
    booktitle = {
        Parallel and Distributed Processing, 2008. IPDPS 2008. IEEE
        International Symposium on
    },
    title = {
        Towards scalable performance analysis and visualization through data
        reduction
    },
    year = { 2008 },
    month = { April },
    pages = { 1-8 },
    abstract = {
        Performance analysis tools based on event tracing are important for
        understanding the complex computational activities and communication
        patterns in high performance applications. The purpose of these tools is
        to help applications scale well to large numbers of processors. However,
        the tools themselves have to be scalable. As application problem sizes
        grow larger to exploit larger machines, the volume of performance trace
        data generated becomes unmanagable especially as we scale to tens of
        thousands of processors. Simultaneously, at analysis time, the amount of
        information that has to be presented to a human analyst can also become
        overwhelming. This paper investigates the effectiveness of employing
        heuristics and clustering techniques in a scalability framework to
        determine a subset of processors whose detailed event traces should be
        retained. It is a form of compression where we retain information from
        processors with high signal content. We quantify the reduction in the
        volume of performance trace data generated by NAMD, a molecular dynamics
        simulation application implemented using CHARM++. We show that, for the
        known performance problem of poor application grainsize, the quality of
        the trace data preserved by this approach is sufficient to highlight the
        problem.
    },
    keywords = {
        data reduction;
        data visualisation;
        multiprocessing systems;
        performance evaluation;
        CHARM++;
        NAMD molecular dynamics simulation;
        clustering techniques;
        event tracing;
        high performance applications;
        scalability framework;
        scalable performance analysis;
        visualization through data reduction;
        Application software;
        Computer science;
        Data visualization;
        High performance computing;
        Humans;
        Information analysis;
        Instruments;
        Performance analysis;
        Scalability;
        Signal processing
    },
    doi = { 10.1109/IPDPS.2008.4536187 },
    ISSN = { 1530-2075 }
}

@inproceedings{
    Schulz:2011,
    author = {
        Schulz, M. and
        Levine, J.A. and
        Bremer, P.-T. and
        Gamblin, T. and
        Pascucci, V.
    },
    booktitle = {
        Parallel Processing (ICPP), 2011 International Conference on
    },
    title = { Interpreting Performance Data across Intuitive Domains },
    year = { 2011 },
    month = { Sept },
    pages = { 206-215 },
    abstract = {
        To exploit the capabilities of current and future systems, developers
        must understand the interplay between on-node performance, domain
        decomposition, and an application's intrinsic communication patterns.
        While tools exist to gather and analyze data for each of these
        components individually, the resulting information is generally
        processed in isolation and presented in an abstract, categorical fashion
        unintuitive to most users. In this paper we present the HAC model, in
        which we identify the three domains of performance data most familiar to
        the user: (i)the application domain containing the application's working
        set, (ii) the hardware domain of the compute and network devices, and
        (iii) the communication domain of logical data transfers. We show that
        taking data from each of these domains and projecting, visualizing, and
        correlating it to the other domains can give valuable insights into the
        behavior of parallel application codes. The HAC abstraction opens the
        door for a new generation of tools that can help users more easily and
        intuitively associate performance data with root causes in the hardware
        system, the application's structure, and in its communication behavior,
        and by doing so leads to an improved understanding of the performance of
        their codes.
    },
    keywords = {
        data handling;
        data visualisation;
        parallel processing;
        application domain;
        communication domain;
        data correlation;
        data projection;
        data visualization;
        domain decomposition;
        hardware domain;
        intrinsic communication pattern;
        on-node performance;
        parallel application code;
        performance data interpretation;
        Analytical models;
        Computational modeling;
        Data models;
        Data visualization;
        Hardware;
        Measurement;
        Program processors;
        Performance Analysis and Visualization
    },
    doi = { 10.1109/ICPP.2011.60 },
    ISSN = { 0190-3918 }
}

@inproceedings{
    Moscovich:2009,
    author = {
        Moscovich, Tomer and
        Chevalier, Fanny and
        Henry, Nathalie and
        Pietriga, Emmanuel and
        Fekete, Jean-Daniel
    },
    title = { Topology-aware Navigation in Large Networks },
    booktitle = {
        Proceedings of the SIGCHI Conference on Human Factors in Computing
        Systems
    },
    series = { CHI '09 },
    year = { 2009 },
    isbn = { 978-1-60558-246-7 },
    location = { Boston, MA, USA },
    pages = { 2319--2328 },
    numpages = { 10 },
    url = { http://doi.acm.org/10.1145/1518701.1519056 },
    doi = { 10.1145/1518701.1519056 },
    acmid = { 1519056 },
    publisher = { ACM },
    address = { New York, NY, USA },
    abstract = {
        Applications supporting navigation in large networks are used every days
        by millions of people. They include road map navigators, flight route
        visualization systems, and network visualization systems using node-link
        diagrams. These applications currently provide generic interaction
        methods for navigation: pan-and-zoom and sometimes bird's eye views.
        
        This article explores the idea of exploiting the connection information
        provided by the network to help navigate these large spaces. We visually
        augment two traditional navigation methods, and develop two
        special-purpose techniques. The first new technique, called "Link
        Sliding", provides guided panning when continuously dragging along a
        visible link. The second technique, called "Bring & Go", brings adjacent
        nodes nearby when pointing to a node. We compare the performance of
        these techniques in both an adjacency exploration task and a node
        revisiting task. This comparison illustrates the various advantages of
        content-aware network navigation techniques. A significant speed
        advantage is found for the Bring & Go technique over other methods.
    },
    keywords = {
        content-aware;
        document navigation;
        graph visualization;
        interaction techniques
    }
}

@article{
    Chan:2007,
	title = {
        An Efficient Format for Nearly Constant-Time Access to Arbitrary Time
        Intervals in Large Trace Files
    },
	author = {
        A. Chan and
        W. D. Gropp and
        Ewing L. Lusk
    },
	journal = { Sci. Programming },
    volume = { 16 },
    year = { 2007 },
    pages = { 155-165 },
    abstract = {
        A powerful method to aid in understanding the performance of parallel
        applications uses log or trace files containing time-stamped events and
        states (pairs of events). These trace files can be very large, often
        hundreds or even thousands of megabytes. Because of the cost of
        accessing and displaying such files, other methods are often used that
        reduce the size of the tracefiles at the cost of sacrificing detail or
        other information.

        This paper describes a hierarchical trace file format that provides for
        display of an arbitrary time window in a time independent of the total
        size of the file and roughly proportional to the number of events within
        the time window. This format eliminates the need to sacrifice data to
        achieve a smaller trace file size (since storage is inexpensive, it is
        necessary only to make efficient use of bandwidth to that storage). The
        format can be used to organize a trace file or to create a separate file
        of annotations that may be used with conventional trace files. We
        present an analysis of the time to access all of the events relevant to
        an interval of time and we describe experiments demonstrating the
        performance of this file format.
    }
}

@inproceedings{
    Wu:2000,
    author = {
        Wu, C.E. and
        Bolmarcich, A. and
        Snir, M. and
        Wootton, D. and
        Parpia, F. and
        Chan, A. and
        Lusk, E. and
        Gropp, W.
    },
    booktitle = { Supercomputing, ACM/IEEE 2000 Conference },
    title = {
        From Trace Generation to Visualization: A Performance Framework for
        Distributed Parallel Systems
    },
    year = { 2000 },
    month = { Nov },
    pages = { 50-50 },
    abstract = {
        In this paper we describe a trace analysis framework, from trace
        generation to visualization. It includes a unified tracing facility on
        IBMâ SPä systems, a self-defining interval file format, an API for
        framework extensions, utilities for merging and statistics generation,
        and a visualization tool with preview and multiple time-space diagrams.
        The trace environment is extremely scalable, and combines MPI events
        with system activities in the same set of trace files, one for each SMP
        node. Since the amount of trace data may be very large, utilities are
        developed to convert and merge individual trace files into a
        self-defining interval trace file with multiple frame directories. The
        interval format allows the development of multiple time-space diagrams,
        such as thread-activity view, processor-activity view, etc., from the
        same interval file. A visualization tool, Jumpshot, is modified to
        visualize these views. A statistics utility is developed using the API,
        along with its graphics viewer.
    },
    keywords = {
        SMP clusters;
        distributed parallel systems;
        file format;
        interval;
        multiple time-space diagrams;
        trace generation;
        trace visualization;
        Clocks;
        Computer science;
        Data analysis;
        Data visualization;
        Laboratories;
        Mathematics;
        Performance
        analysis;
        Processor scheduling;
        Synchronization;
        Yarn;
        SMP clusters;
        distributed parallel systems;
        file format;
        interval;
        multiple time-space diagrams;
        trace generation;
        trace visualization
    },
    doi = { 10.1109/SC.2000.10050 },
    ISSN = { 1063-9535 }
}

@inproceedings{
    Karrels:1994,
    title = { Performance analysis of MPI programs },
    author = { Karrels, Edward and Lusk, Ewing },
    booktitle = {
        Proceedings of the Workshop on Environments and Tools For Parallel
        Scientific Computing
    },
    pages = { 195--200 },
    abstract = {
        The Message Passing Interface (MPI) standard has recently been
        completed. MPI is a specication for a library of functions that
        implement the message-passing model of parallel computation. One novel
        feature of MPI is its very general "profiling interface," that allows
        users to attach assorted profiling tools to the MPI library even though
        they do not have access to the MPI source code. We describe the MPI
        profiling interface and describe three profiling libraries that make use
        of it. These libraries are distributed with the portable, publicly
        available implementation of MPI.
    },
    year = { 1994 }
}

@techreport{
    Herrarte:1991,
    title = { Studying parallel program behavior with upshot },
    author = { Herrarte, Virginia and Lusk, Ewing },
    booktitle = { Technical Report ANL-91/15 },
    year = { 1991 },
    institution = { Argonne National Lab., IL (United States) }
}

@article{
    Heath:1994,
    title = {
        ParaGraph: A tool for visualizing performance of parallel programs
    },
    author = { Heath, Michael T and Finger, Jennifer Etheridge },
    journal = {
        Second Workshop on Environments and Tools for Parallel Sci.  Comput.
    },
    pages = { 221--230 },
    year = { 1994 },
    publisher = { Oak Ridge National Lab, Oak Ridge, TN }
}

@article{
    Heath:1991,
    author = {
        Heath, Michael T and
        Etheridge, J.A.
    },
    journal = { Software, IEEE },
    title = { Visualizing the performance of parallel programs },
    year = { 1991 },
    month = { Sept },
    volume = { 8 },
    number = { 5 },
    pages = { 29--39 },
    abstract = {
        ParaGraph, a software tool that provides a detailed, dynamic, graphical
        animation of the behavior of message-passing parallel programs and
        graphical summaries of their performance, is presented. ParaGraph
        animates trace information from actual runs to depict behavior and
        obtain the performance summaries. It provides twenty-five perspectives
        on the same data, lending insight that might otherwise be missed.
        ParaGraph's features are described, its use is explained, its software
        design is briefly discussed, and its displays are examined in some
        detail. Future work on ParaGraph is indicated.
    },
    keywords = {
        computer animation;
        parallel programming;
        performance evaluation;
        program testing;
        software tools;
        ParaGraph;
        dynamic animation;
        graphical animation;
        graphical summaries;
        message-passing parallel programs;
        performance summaries;
        performance visualization;
        software design;
        software tool;
        trace information;
        Animation;
        Bandwidth;
        Data mining;
        Data visualization;
        Displays;
        Humans;
        Impedance;
        Monitoring;
        Performance gain;
        Workstations
    },
    doi = { 10.1109/52.84214 },
    ISSN = { 0740-7459 }
}

@book{
    Nagel:1996,
    title = { VAMPIR: Visualization and analysis of MPI resources },
    author = {
        Nagel, Wolfgang E and
        Arnold, Alfred and
        Weber, Michael and
        Hoppe, Hans-Christian and
        Solchenbach, Karl
    },
    journal = { Supercomputer },
    volume = { 12 },
    number = { 1 },
    pages = { 69--80 },
    year = { 1996 }
}

@article{
    Shende:2006,
    title = { The TAU parallel performance system },
    author = { Shende, Sameer S and Malony, Allen D },
    journal = {
        International Journal of High Performance Computing Applications
    },
    volume = { 20 },
    number = { 2 },
    pages = { 287--311 },
    year = { 2006 }
}

@article{
    Shaffer:1999,
    title = {
        Virtue: Performance visualization of parallel and distributed
        applications
    },
    author = {
        Shaffer, Eric and
        Reed, Daniel A and
        Whitmore, Shannon and
        Schaeffer, Benjamin
    },
    journal = { Computer },
    volume = { 32 },
    number = { 12 },
    pages = { 44--51 },
    year = { 1999 },
    publisher = { IEEE }
}

@article{
    Topol:1998,
    title = {
        PVaniM: A tool for visualization in network computing environments
    },
    author = {
        Topol, Brad and
        Stasko, John T and
        Sunderam, Vaidy
    },
    journal = { Concurrency: Practice and Experience },
    volume = { 10 },
    number = { 14 },
    pages = { 1197--1222 },
    year = { 1998 }
}

@incollection{
    Kranzlmuller:1998,
    title = { Debugging point-to-point communication in MPI and PVM },
    author = { Kranzlm{\"u}ller, Dieter and Volkert, Jens },
    booktitle = {
        Recent Advances in Parallel Virtual Machine and Message Passing
        Interface
    },
    pages = { 265--272 },
    year = { 1998 },
    publisher = { Springer }
}

@inproceedings{
    Kranzlmuller:1996,
    title = { Debugging massively parallel programs with ATEMPT },
    author = {
        Kranzlm{\"u}ller, Dieter and
        Grabner, Siegfried and
        Volkert, Jens
    },
    booktitle = { High-Performance Computing and Networking },
    pages = { 806--811 },
    year = { 1996 },
    organization = { Springer }
}

@inproceedings{
    Jerding:1997,
    title = { Visualizing interactions in program executions },
    author = {
        Jerding, Dean F and
        Stasko, John T and
        Ball, Thomas
    },
    booktitle = {
        Proceedings of the 19th international conference on Software engineering
    },
    pages = { 360--370 },
    year = { 1997 },
    organization = { ACM }
}

@inproceedings{
    Moreta:2007,
    title = { Multiscale visualization of dynamic software logs },
    author = { Moreta, Sergio and Telea, Alexandru },
    booktitle = {
        Proceedings of the 9th Joint Eurographics/IEEE VGTC conference on
        Visualization
    },
    pages = { 11--18 },
    year = { 2007 },
    organization = { Eurographics Association }
}

@article{
    Cornelissen:2008,
    title = {
        Execution trace analysis through massive sequence and circular bundle
        views
    },
    author = {
        Cornelissen, Bas and
        Zaidman, Andy and
        Holten, Danny and
        Moonen, Leon and
        van Deursen, Arie and
        van Wijk, Jarke J
    },
    journal = { Journal of Systems and Software },
    volume = { 81 },
    number = { 12 },
    pages = { 2252--2268 },
    year = { 2008 },
    publisher = { Elsevier }
}

@inproceedings{
    Brandt:2009,
    author = {
        Brandt, J. and
        Gentile, A. and
        Mayo, J. and
        Pebay, P. and
        Roe, D. and
        Thompson, D.
        and Wong, M.
    },
    booktitle = {
        Parallel Distributed Processing, 2009. IPDPS 2009. IEEE International
        Symposium on
    },
    title = {
        Resource monitoring and management with OVIS to enable HPC in cloud
        computing environments
    },
    year = { 2009 },
    month = { May },
    pages = { 1--8 },
    abstract = {
        Using the cloud computing paradigm, a host of companies promise to make
        huge compute resources available to users on a pay-as-you-go basis.
        These resources can be configured on the fly to provide the hardware and
        operating system of choice to the customer on a large scale. While the
        current target market for these resources in the commercial space is Web
        development/hosting, this model has the lure of savings of ownership,
        operation, and maintenance costs, and thus sounds like an attractive
        solution for people who currently invest millions to hundreds of
        millions of dollars annually on high performance computing (HPC)
        platforms in order to support large-scale scientific simulation codes.
        Given the current interconnect bandwidth and topologies utilized in
        these commercial offerings, however, the only current viable market in
        HPC would be small-memory-footprint embarrassingly parallel or loosely
        coupled applications, which inherently require little to no
        inter-processor communication. While providing the appropriate resources
        (bandwidth, latency, memory, etc.) for the HPC community would increase
        the potential to enable HPC in cloud environments, this would not
        address the need for scalability and reliability, crucial to HPC
        applications. Providing for these needs is particularly difficult in
        commercial cloud offerings where the number of virtual resources can far
        outstrip the number of physical resources, the resources are shared
        among many users, and the resources may be heterogeneous. Advanced
        resource monitoring, analysis, and configuration tools can help address
        these issues, since they bring the ability to dynamically provide and
        respond to information about the platform and application state and
        would enable more appropriate, efficient, and flexible use of the
        resources key to enabling HPC. Additionally such tools could be of
        benefit to non-HPC cloud providers, users, and applications by providing
        more efficient resource utilization in general.
    },
    keywords = {
        Internet;
        operating systems (computers);
        system monitoring;
        OVIS;
        Web development;
        Web hosting;
        cloud computing environments;
        high performance computing platforms;
        operating system;
        pay-as-you-go basis;
        resource monitoring;
        scientific simulation codes;
        Bandwidth;
        Cloud computing;
        Costs;
        Environmental management;
        Hardware;
        High performance computing;
        Large-scale systems;
        Monitoring;
        Operating systems;
        Resource management
    },
    doi = { 10.1109/IPDPS.2009.5161234 },
    ISSN = { 1530-2075}
}

@misc{
    threejs,
    author = { Ricardo Cabello },
    title = { three.js - JavaScript 3D library },
    month = { April },
    year = { 2014 },
    url = { http://www.threejs.org }
}

@misc{
    webgl,
    author = {{ The Khronos Group}},
    title = { WebGL - OpenGL ES 2.0 for the Web },
    month = { April },
    year = { 2014 },
    url = { http://www.khronos.org/webgl }
}

